{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devarshi167/Netflix-movies-and-TV-shows-clustering/blob/main/Copy_of_Copy_of_Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - NETFLIX MOVIES AND TV SHOWS CLUSTERING\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised ML\n"
      ],
      "metadata": {
        "id": "TeOoVzU8yeOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Contribution**    - Team"
      ],
      "metadata": {
        "id": "pkl91xE7yg2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### **Team Member 1 -**Devarshi Dwivedi\n",
        "##### **Team Member 2 -**Jay Pardesi\n",
        "##### **Team Member 3 -**Priyadarshini Gaikwad\n",
        "##### **Team Member 4 -**Samarjeet Singh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix, Inc. is an American subscription video on-demand over-the-top streaming service and production company based in Los Gatos, California. Founded in 1997 by Reed Hastings and Marc Randolph in Scotts Valley, California, it offers a film and television series library through distribution deals as well as its own productions, known as Netflix Originals.\n",
        "\n",
        "For further details, visit [Netflix Help Center](https://help.netflix.com/en/node/412)\n",
        "\n",
        "We will be exploring the dataset further to draw insights."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Netflix-movies-and-TV-shows-clustering](https://github.com/devarshi167Netflix-movies-and-TV-shows-clustering)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **In this project, we are required to perform the following-**\n"
      ],
      "metadata": {
        "id": "Ua5ClmijwAhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Exploratory Data Analysis\n",
        "\n",
        "2. Understanding what type content is available in different countries\n",
        "\n",
        "3. Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4. Clustering similar content by matching text-based features\n",
        "\n"
      ],
      "metadata": {
        "id": "hZn2UxhrwNqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Description-**\n"
      ],
      "metadata": {
        "id": "EGrwzLXIz22y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "* type : Identifier - A Movie or TV Show\n",
        "\n",
        "* title : Title of the Movie / Tv Show\n",
        "\n",
        "* director : Director of the Movie\n",
        "\n",
        "* cast : Actors involved in the movie / show\n",
        "\n",
        "* country : Country where the movie / show was produced\n",
        "\n",
        "* date_added : Date it was added on Netflix\n",
        "\n",
        "* release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "* rating : TV Rating of the movie / show\n",
        "\n",
        "* duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "* listed_in : Genere\n",
        "\n",
        "* description: The Summary description"
      ],
      "metadata": {
        "id": "xHUWefOS0A9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# library used for Analyzing and Visualization purpose\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# library used for textual data prerocessing\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# library used for Clusters impelementation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "QKAqo0KqHaVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings library. Would help to throw away warnings caused.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vWSrOYCpHjmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING ML Capstone project- Devarshi Dwivedi/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "rNaw7stuDeUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "ildQ1yu2Fnby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df[df.duplicated()].sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated(subset=['title']).value_counts()"
      ],
      "metadata": {
        "id": "JUhJPPTrBc7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.heatmap(df.isna(), yticklabels = False)\n",
        "plt.xlabel('Column Name')\n",
        "plt.title('Null values', fontweight = 'bold', size =18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are total 7787 rows and 12 columns in this dataset. \n",
        "* All columns are of object data type except the release_year which is of int type.\n",
        "* There are no duplicate value in this data set but there are many null values present in this dataset \n",
        "* Columns with null values are director, cast, country, date_added and rating"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is only one int type column in this dataset which is realease_year with total count : 7787, min : 1925, max : 2021, 50% : 2017, mean : 2013.9"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df['show_id'].unique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].unique()"
      ],
      "metadata": {
        "id": "TYplQiL1N1JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'].unique()"
      ],
      "metadata": {
        "id": "OssQnRlpOiBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['director'].unique()"
      ],
      "metadata": {
        "id": "2lHapJaZOiJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cast'].unique()"
      ],
      "metadata": {
        "id": "aQZHAf8wOiNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['country'].unique()"
      ],
      "metadata": {
        "id": "aONo1mUDOiRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_added'].unique()"
      ],
      "metadata": {
        "id": "kd2Vv03XOiUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['release_year'].unique()"
      ],
      "metadata": {
        "id": "7eCa8dBTOiXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "3lM9fpygOicC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['duration'].unique()"
      ],
      "metadata": {
        "id": "o0P5zTaoOine"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['listed_in'].unique()"
      ],
      "metadata": {
        "id": "iA-eQZP8PCg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'].unique()"
      ],
      "metadata": {
        "id": "Yca_zHMHPCjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Null Values Treatment"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing missing values in 'director' column with Not Mention\n",
        "df['director'].replace(np.nan, 'Not Mention', inplace = True)\n",
        "\n",
        "#Replacing missing values in 'cast' column with Not Mention\n",
        "df['cast'].replace(np.nan, 'Not Mention', inplace = True)\n",
        "\n",
        "#Replacing missing values in 'country' column with mode\n",
        "df['country']= df['country'].fillna(df['country'].mode()[0])\n",
        "\n",
        "#Replacing missing values in 'rating' column with value most frequent rating i.e. mode\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mode()[0])\n",
        "\n",
        "# Dropping the null values in 'date_added'\n",
        "df = df[df['date_added'].notna()]\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "x4sWP2vwXcg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into a date-time format\n",
        "df['date_added'] = pd.to_datetime(df['date_added'])\n",
        "\n",
        "# Adding new column year added to get year in which movie is added to netflix\n",
        "df['year_added'] = df['date_added'].dt.year\n",
        "df['year_added'].astype(int)\n"
      ],
      "metadata": {
        "id": "C_92Fxm5YEQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the ‘listed_in’ feature to the genre for easy use.\n",
        "df = df.rename(columns={\"listed_in\":\"genere\"})\n",
        "df['genere'] = df['genere'].apply(lambda x: x.split(\",\")[0])\n"
      ],
      "metadata": {
        "id": "tvm0eMSBZUOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['genere'].unique()"
      ],
      "metadata": {
        "id": "YoAVUN9eeo50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "knEsqRdbZ5ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "I0ncZbB2aA3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Replaced missing values in 'director' and 'cast' column with Not Mention.\n",
        "* Replaced missing values in 'country' and 'rating' column with mode.\n",
        "* Dropped the null values in 'date_added'.\n",
        "* 'date_added' column coverted into datetime dtyape and also added new column called 'year_added'.\n",
        "* renamed 'listed_in' column to 'genere' and splited it for getting genere for easy use of info. "
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Pie Chart between the TV- Shows and Movies of Netflix Dataset.\n",
        "plt.figure(figsize = (10,6))\n",
        "content = ['TV Show','Movie']\n",
        "plt.pie(df['type'].value_counts().sort_values(), labels = content,autopct='%1.2f%%',shadow=True)\n",
        "plt.title('Type of Netflix Content',fontweight='bold')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **There are more Movies on Netflix than TV Shows**"
      ],
      "metadata": {
        "id": "NYSPN-Regy2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text documents\n",
        "text = \" \".join(word for word in df['title'])\n",
        "\n",
        "# create the word cloud\n",
        "wordcloud = WordCloud(stopwords=STOPWORDS).generate(text)\n",
        "\n",
        "# plot the word cloud\n",
        "plt.imshow(wordcloud,  interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xaOUagnZIK1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words like Christmas, Love, World, Man, Story are very common in movie title column."
      ],
      "metadata": {
        "id": "MFU5vAsWK7ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2, figsize=(18,6))\n",
        "plt.suptitle('Top 10 country with the highest number of movie/shows', weight='bold', size=15, y=1.01)\n",
        "\n",
        "# univariate analysis\n",
        "df['country'].value_counts().nlargest(10).plot(kind='barh', ax=ax[0]) #sns.countplot(x=\"country\", data=df, order=df['country'].value_counts().index[0:10], ax=ax[0])\n",
        "\n",
        "# bivariate analysis\n",
        "graph = sns.countplot(x=\"country\", data=df, hue='type', order=df['country'].value_counts().index[0:10], ax=ax[1])\n",
        "plt.xticks(rotation=90)\n",
        "for p in graph.patches:  #adding value count on the top of bar\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIPEBSmaI0ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest number of movies / TV shows were based out of the US, followed by India and UK."
      ],
      "metadata": {
        "id": "7dXNX0duLihR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding number of movies and TV shows\n",
        "plt.figure(figsize=(10,6))\n",
        "p = sns.countplot(df.type)\n",
        "plt.title(\"Count of Movies and TV Shows\")\n",
        "#plt.xlabel(\"Type (Movie/TV Show)\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rtvmg-BWgUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting number of movies and TV shows with respect to year_added\n",
        "df_tv = df[df['type'] == 'TV Show']\n",
        "df_movies = df[df['type'] == 'Movie']\n",
        "year_df = df.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "movies_year_df = df_movies.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "shows_year_df = df_tv.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "year_df.sort_values(by=['year'])"
      ],
      "metadata": {
        "id": "I8ELIY9uipSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **We can see that after consistently increase in number of count till year 2019-2020 there is sudden drop in year 2021 due to COVID.** \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PuYpwKPFk9mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text documents\n",
        "text = \" \".join(word for word in df['description'])\n",
        "\n",
        "# create the word cloud\n",
        "wordcloud = WordCloud(stopwords=STOPWORDS).generate(text)\n",
        "\n",
        "# plot the word cloud\n",
        "plt.imshow(wordcloud,  interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "66Ma8fevJe7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the common words present in description column are family, find, life, love, new, world, friend etc."
      ],
      "metadata": {
        "id": "_Xaz-YwVNFvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the plot for Top 10 Country on Netflix.\n",
        "\n",
        "df['top_country']=df['country'].apply(lambda x:x.split(',')[0])\n",
        "plt.figure(figsize = (10,6))\n",
        "ax = sns.countplot(x='top_country', data=df,order=df['top_country'].value_counts().index[:10])\n",
        "plt.title('Top 10 Countries on Netflix',fontweight='bold')\n",
        "plt.xlabel('country',fontweight='bold',fontsize=12)\n",
        "plt.ylabel('counts',fontweight='bold',fontsize=10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vQFI0dhAk72J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **US is at top about content on Netflix followed by India and UK respectivly.**"
      ],
      "metadata": {
        "id": "eVotynm8m-xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of TV Shows VS Movies content in top 10 countries with maximum content\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "ax = sns.countplot(y='top_country',data=df,hue='type',order=df['top_country'].value_counts().index[:10])\n",
        "plt.ylabel('Country',fontweight='bold')\n",
        "plt.title(\"Number of TV Shows and Movies in top 10 countries\",fontweight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MDZp2EI2iqFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Most of the countries have more movies than TV shows, But you can see that for South Korea and Japan it's the opposite. It maybe because KDramas are more popular in S Korea and Anime are more popular in Japan.**"
      ],
      "metadata": {
        "id": "__toguncpvXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rating based on Rating System of all the movies\n",
        "\n",
        "movie_ratings = df_movies.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "fig_s = (10,6)\n",
        "fig, ax = plt.subplots(figsize = fig_s)\n",
        "sns.pointplot(x='rating',y='count',data=movie_ratings)\n",
        "plt.title('Top Movie Ratings Based On Rating System',size='18',fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zCd7KeeDiqHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2, figsize=(18,6))\n",
        "\n",
        "# Univariate analysis\n",
        "hist = sns.histplot(df['release_year'], ax=ax[0])\n",
        "hist.set_title('distribution by released year', size=15)\n",
        "\n",
        "# Bivariate analysis\n",
        "count = sns.countplot(x=\"release_year\", hue='type', data=df, order=df['release_year'].value_counts().index[0:15], ax=ax[1])\n",
        "count.set_title('movie/shows release in top 15 year', size=15)\n",
        "plt.xticks(rotation=90)\n",
        "for p in count.patches:  #adding value count on the top of bar\n",
        "   count.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G1DRpThgJEM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "1. Netflix has greater number of new movies / TV shows than the old ones.\n",
        "2. Highest number of movie/shows are released in netflix in between 2015-2020 and highest number of count comes from 2018."
      ],
      "metadata": {
        "id": "M0MKVcrSMUCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Most number of movies rated TV-MA i.e. Adult Rating**"
      ],
      "metadata": {
        "id": "zn0TlYTbsuCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rating based on Rating System of all the TV Shows\n",
        "shows_ratings=df_tv.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "fig,ax=plt.subplots(figsize=(14,7))\n",
        "sns.pointplot(x='rating',y='count',data=shows_ratings)\n",
        "plt.title('Top TV Shows Ratings Based on Rating System',size='20',fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydQxU9R0iqKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Most number of TV Shows rated TV-MA i.e. Adult Rating**"
      ],
      "metadata": {
        "id": "gD3Wm1-DtPpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "direc=df.copy()\n",
        "#removing unknown \n",
        "direc=direc[df['director']!='Not Mention']\n",
        "\n",
        "# Top 10 director whose content is available in netflix\n",
        "\n",
        "plt.figure(figsize = (14,6))\n",
        "sns.countplot(y='director',data=direc,order=direc.director.value_counts().head(10).index,palette='cubehelix')\n",
        "plt.title('Director with most movies/shows',fontweight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F8lr0BYAiqNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Raul Campos and Jan Sulter collectively have the most content on Netflix followed by Marcus and Jay respectivly.**\n",
        "\n"
      ],
      "metadata": {
        "id": "ruMpsHS_wLkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting plot for top actors\n",
        "\n",
        "#splitting into list\n",
        "df['cast_name'] = df['cast'].apply(lambda x :  x.split(',')) \n",
        "cast_count = []\n",
        "\n",
        "#count movies for each actor\n",
        "for i in df['cast_name']: cast_count += i\n",
        "    \n",
        "cast_dict = dict((i, cast_count.count(i)) for i in cast_count)\n",
        "\n",
        "df_cast_count = pd.DataFrame(cast_dict.values(),cast_dict.keys()).reset_index().sort_values(0,ascending=False).rename(\n",
        "    columns = {'index' : 'cast_name', 0 : 'count'}).iloc[1:11]\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.barplot(y='cast_name',x='count',data=df_cast_count,palette=\"viridis\")\n",
        "plt.title(\"Top 10 ACTORS on Netflix\",size='16',fontweight=\"bold\")\n",
        "plt.xlabel('Cast Name')\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "Tob2ZKHKiqXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Anupam Kher Have the most number of films on Netflix followed by Takahiro Sakurai And Shah Rukh Khan.**\n"
      ],
      "metadata": {
        "id": "hxo_7-xcxezB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing how many movies released per year in last 10 years\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('ANALYSIS ON RELEASE YEAR OF MOVIES IN LAST 10 YEARS', fontsize=15, fontweight='bold')\n",
        "sns.countplot(x=df_movies['release_year'],data=df_movies,order=df_movies['release_year'].value_counts().index[0:10],palette='viridis')"
      ],
      "metadata": {
        "id": "0AG02eAKx3mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing how many TV SHOWS released per year in last 10 years\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('ANALYSIS ON RELEASE YEAR OF TV SHOWS IN LAST 10 YEARS', fontsize=15, fontweight='bold')\n",
        "sns.countplot(x=df_tv['release_year'],data=df_tv,order=df_tv['release_year'].value_counts().index[0:10],palette=\"viridis\")"
      ],
      "metadata": {
        "id": "w857fDncx3pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 genres on Netflix\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "ax = sns.countplot(y=df['genere'], order=df['genere'].value_counts().index[:10],palette='viridis')\n",
        "plt.title('Top 10 genere on Netflix', fontweight='bold')"
      ],
      "metadata": {
        "id": "3G2cBnlSx3t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Drama is the most popular genre followed by comedy on Netflix.**\n",
        "\n"
      ],
      "metadata": {
        "id": "3rWc6PVJ9Tev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Originally Uploaded on Netflix:**\n",
        "* some movies and TV shows were actually released in the past and they were added later on Netflix.\n",
        "* But some movies and TV shows were released on Netflix itself. Named those as Netflix Originals.\n",
        "\n",
        "\n",
        "Originals: For which released year and added year is same."
      ],
      "metadata": {
        "id": "jV89MOTr2luH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new feature as originals having values Yes and No.\n",
        "df['originals'] = np.where(df['release_year']==df['year_added'], 'Yes', 'No')"
      ],
      "metadata": {
        "id": "i1qQCnmC2fne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "plt.pie(df['originals'].value_counts().sort_values(), labels= ['Others', 'Originals'],autopct='%1.2f%%',shadow=True)\n",
        "plt.title('Netflix Original',fontweight='bold')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NGH3Ixh6x4CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Through this plot we can say that 63.67% content is Netflix original.**"
      ],
      "metadata": {
        "id": "jID53VQp46Yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Is Netflix has increasingly focusing on TV rather than movies in recent years?**"
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Testing to check is there is any relation between year_added and type:\n",
        "\n",
        "* *Null Hypothesis:* year_added has no impact on type of content that gets added to the platform.\n",
        "* *Alternative Hypothesis:* year_added has impact on type of content that gets added to the platform."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypo_data = pd.crosstab(df['type'], df['year_added'], margins=False)\n",
        "hypo_data"
      ],
      "metadata": {
        "id": "pqXc-SJYGIij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chisquare\n",
        "from scipy.stats import chi2_contingency\n",
        "chi2_contingency(hypo_data) \n"
      ],
      "metadata": {
        "id": "s-A7-5sVGUto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The p value is smaller than significance level , we will reject the null hypothesis and accept the alternative hypothesis."
      ],
      "metadata": {
        "id": "j3Su12j9MGb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Text Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import important libraries for text preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "vZjxq1m-_Gr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Function to remove punctuations\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "\n",
        "    import string\n",
        "    \n",
        "    # replacing the punctuations with no space, \n",
        "    # which in effect deletes the punctuation marks \n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "reN_U6sd_GuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the function to remove punctuations\n",
        "df['description'] = df['description'].apply(remove_punctuation)\n",
        "\n",
        "# Applying the function to remove punctuations\n",
        "df['genere'] = df['genere'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "uEPZOhhZ_Gx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing natural language tool kit\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "O4J1Eb5s_G1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the stopwords from nltk library\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "# Function to remove stopwords \n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "DyUftc-W_G4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the stopword function\n",
        "df['description'] = df['description'].apply(stopwords)\n",
        "\n",
        "# Applying the stopword function\n",
        "df['genere'] = df['genere'].apply(stopwords)"
      ],
      "metadata": {
        "id": "shi09O3hAF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "SU0g-jj2Aa2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an object of stemming function\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):    \n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)  "
      ],
      "metadata": {
        "id": "RoQlVS5PAF6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming for description\n",
        "df['description'] = df['description'].apply(stemming)"
      ],
      "metadata": {
        "id": "vTPFOBoGAF9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to display text length\n",
        "def length(text):    \n",
        "    '''a function which returns the length of text'''\n",
        "    return len(text)"
      ],
      "metadata": {
        "id": "UxTRnFvQAF_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two variables for description and listed-in texts length respectively\n",
        "df['desc_length'] = df['description'].apply(length)\n",
        "df['genere_length'] = df['genere'].apply(length)"
      ],
      "metadata": {
        "id": "OHMri2BMAGDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe with variables indicating text lengths only\n",
        "cluster_df=df.filter(['desc_length','genere_length'],axis=1)\n",
        "cluster_df.head(2)"
      ],
      "metadata": {
        "id": "6jSGKRdGBRNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing value to generalise\n",
        "X_features_rec_mon=df[['desc_length','genere_length']]\n",
        "scaler_rec_mon=preprocessing.StandardScaler()\n",
        "X_rec_mon=scaler_rec_mon.fit_transform(X_features_rec_mon)\n",
        "X=X_rec_mon"
      ],
      "metadata": {
        "id": "PsJkHLR6BRQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Our text is preprocessed and ready for algorithms to be applied.** "
      ],
      "metadata": {
        "id": "a0fHGOZ_CwSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Implementing K-means***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score"
      ],
      "metadata": {
        "id": "knsCN5d9C4Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Optimum Numbers of Clusters using Elbow Method**"
      ],
      "metadata": {
        "id": "jCobc0ouDLC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list\n",
        "list_1 = []\n",
        "\n",
        "# for loop to append kmeans inertia values\n",
        "for k in range(1,10):\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    kmeans.fit(X)\n",
        "    list_1.append(kmeans.inertia_)\n",
        "\n",
        "#Plot linegraph\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.plot(range(1,10),list_1,\"-o\")\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Number of Clusters(k)\",fontsize=12)\n",
        "plt.ylabel(\"Sum of Square Distances\",fontsize=12)\n",
        "plt.title(\"Elbow Method For Optimal k\",fontsize=14)\n",
        "plt.xticks(range(1,10))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "dkOUeG-XC4Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above plot, the elbow is at k=3, indicating the optimal k for this dataset is 3. Let us visualise our data for different values of clusters , say 2,3,4,5,6,7,8 , for better understanding."
      ],
      "metadata": {
        "id": "xbeiaOvnDu-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v=2\n",
        "for i in (2,3,4,5,6,7,8):\n",
        "  kmeans = KMeans(n_clusters=i)\n",
        "  kmeans.fit(X)\n",
        "  y_kmeans= kmeans.predict(X)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  n =v+1\n",
        "   \n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, )\n",
        "\n",
        "  centers = kmeans.cluster_centers_\n",
        "  plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)\n",
        "  plt.title((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % i),\n",
        "                 fontsize=14, fontweight='bold')\n"
      ],
      "metadata": {
        "id": "wKzBVFYqC4G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Silhouette scores of different clusters :**"
      ],
      "metadata": {
        "id": "LF6MptFoEkjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhoutte score for K-means\n",
        "\n",
        "range_n_clusters = [2,3,4,5,6,7,8]\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)\n",
        "    preds = clusterer.fit_predict(X)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X, preds)\n",
        "    print(\"\\nFor n_clusters = {}, silhouette score is {}\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "FEVoiTw1C4JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We had already seen earlier that k=3 was optimum for k-means clusterning. and from this score we can see that cluster 7,6,4 are also giving good silhouette score"
      ],
      "metadata": {
        "id": "jIS2OpxhFP9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Heirarchial clustring**"
      ],
      "metadata": {
        "id": "-aCMPDNkHBEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the dendogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Content')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show() # find largest vertical distance we can make without crossing any other horizontal line"
      ],
      "metadata": {
        "id": "e9dpvZQRC4Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of clusters will be the number of vertical lines which are being intersected by the line drawn using the threshold\n",
        "\n",
        "No. of Cluster = 3"
      ],
      "metadata": {
        "id": "dlRAddEUITTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering to the dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc = hc.fit_predict(X)"
      ],
      "metadata": {
        "id": "7pAxsc86H-Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the clusters \n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = '1')\n",
        "plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = '2')\n",
        "plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = '3')\n",
        "\n",
        "\n",
        "plt.title('Clusters of content')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yYsAldDVH-P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhoutte score for HAC( Hierarichal Agglomerative Clustering)\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hac_clusters = [2,3,4,5,6,7,8]\n",
        "for n_clusters in hac_clusters:\n",
        "    clusterer = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "    preds = clusterer.fit_predict(X)\n",
        "\n",
        "    score = silhouette_score(X, preds)\n",
        "    print(\"\\nFor n_clusters = {}, silhouette score is {}\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "oTQWURYrH-cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are about 69.14% movies and 30.86% TV shows on Netflix.\n",
        "\n",
        "* The United States has the highest number of content on Netflix by a huge margin followed by India.\n",
        "\n",
        "* Raul Campos and Jan Sulter collectively have directed the most content on Netflix.\n",
        "\n",
        "* Anupam Kher has acted in the highest number of films on Netflix.\n",
        "\n",
        "* Drama is the most popular genre followed by comedy.\n",
        "\n",
        "* The number of releases have significantly increased after 2015 and have dropped in 2021 because of Covid 19.\n",
        "\n",
        "* NULL HYPOTHESIS -The number of TV shows on Netflix have tripled and The p value is smaller than significance level. (REJECTED)\n",
        "\n",
        "* By using Sillhouette's score and Elbow method , we saw that the elbow is at k=3, indicating the optimal k for this dataset is 3 and cluster 7,6 have also giving good silhouette score.\n",
        "\n",
        "* In both the cases, one cluster accounts more than 3000 points whereas in other clusters the points were unevenly distributed. 3.For Tfidf K Means is best for identification than Hierarchical as the evaluation metrics also indicates the same."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}